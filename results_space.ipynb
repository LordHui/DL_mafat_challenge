{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results_space.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytq6o5ZRmwwg",
        "outputId": "a7d106f0-d437-4437-9460-060387613c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Optional: mounting to Google Drive to read the data files.\n",
        "from google.colab import drive\n",
        "mount_path = '/content/gdrive'\n",
        "drive.mount(mount_path)\n",
        "notebook_root = 'gdrive/My Drive/mafat'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ys8lHQ-arQZ",
        "outputId": "c5e71ca8-b38e-4822-8828-b3a731f2116c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "%cd '/content/gdrive/My Drive/mafat'\n",
        "!pip install torch-stft\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive//My Drive/mafat')\n",
        "\n",
        "from network_support import * \n",
        "from support_files import *\n",
        "\n",
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from math import pi as pi\n",
        "\n",
        "\n",
        "# Public test set - loading and preprocessing\n",
        "train_path = 'Phase 2 - Private/MAFAT RADAR Challenge - FULL Public Test Set V1'\n",
        "test_df = load_data(train_path)\n",
        "test_df = data_preprocess(test_df, mode = 0)\n",
        "print(\"Done with train_df...\")\n",
        "describe_dict(test_df, \"Test DF\")\n",
        "snrs = ['low_snr', 'high_snr']"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1CjXe8JAlTXTHOBVrITA52MQVVfPU_uah/mafat\n",
            "Requirement already satisfied: torch-stft in /usr/local/lib/python3.6/dist-packages (0.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-stft) (1.18.5)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from torch-stft) (0.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-stft) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->torch-stft) (0.16.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->torch-stft) (2.1.8)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->torch-stft) (0.48.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa->torch-stft) (1.15.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->torch-stft) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->torch-stft) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->torch-stft) (0.22.2.post1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->torch-stft) (50.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->torch-stft) (0.31.0)\n",
            "Done with train_df...\n",
            "######  Test DF  #########################################\n",
            "Length: 284\n",
            "Total 0 count: 138\n",
            "Total 1 count: 146\n",
            "Unique Devices: [ 1  4 14]\n",
            "Shape of Images: (284, 126, 32)\n",
            "###########################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xP7nEd0S0WPB"
      },
      "source": [
        "#TESTING RESULTS OF MODELS\n",
        "####To test the results of all trained models in the train_space, you need to know the folder to which the state was saved, the version number of the state, the state's save_name (which should be the name of the model along with a descrptive phrase of the variant), and the model handler. Ensure that all this information is correct in the variables specified. The output is the AUC ROC for each fold trained, along with the ensemble. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV8PZ0UalVRx",
        "outputId": "50b8969a-0fe1-4cf0-a779-53561dda9c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "for snr in snrs:\n",
        "  \n",
        "  ########################\n",
        "  ########################      fix these variables to match the folder and states of interest\n",
        "  batch_size = 32\n",
        "  model_folder = \"others\"\n",
        "  device = 'cuda'\n",
        "  version_number = 1\n",
        "  model_name = f\"net6_{snr}\"\n",
        "  model = Net6().to(device)\n",
        "  folds = 5\n",
        "  ########################\n",
        "  ########################\n",
        "\n",
        "  print(f\"TRAINING SNR TYPE: {snr}, MODEL: {model_name}\\n\")\n",
        "\n",
        "  submission =  pd.DataFrame()\n",
        "  submission['segment_id'] = test_df['segment_id']\n",
        "  save_name = f'v{version_number}_{model_name}_final'\n",
        "\n",
        "  for i in range(folds):\n",
        "      submission[f'fold {i}'] = show_validation_accuracy_two(test_df['iq_sweep_burst'].reshape(list(test_df['iq_sweep_burst'].shape) + [1]), None, i, model_folder, save_name, model, batch_size, 0)\n",
        "      out = pred_description(submission[f'fold {i}'], test_df['target_type'].astype(int), True)\n",
        "      print(f\"ROC-AUC: {out['ROC_AUC']}\")\n",
        "  \n",
        "  submission['prediction'] = submission[[f'fold {j}' for j in range(folds)]].median(1).astype('float')\n",
        "  out = pred_description(submission['prediction'], test_df['target_type'].astype(int), True)\n",
        "  print(f\"ROC-AUC: {out['ROC_AUC']}\")\n",
        "  print('\\n')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING SNR TYPE: low_snr, MODEL: net6_low_snr\n",
            "\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.8426146515783205\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.8344748858447489\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.8392396267619616\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.8617728806829461\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.8721461187214612\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.8559162199722057\n",
            "\n",
            "\n",
            "TRAINING SNR TYPE: high_snr, MODEL: net6_high_snr\n",
            "\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.746079015286877\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.783551717292039\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.7623089140361325\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.7949672424061942\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.7688604327973\n",
            "Number of Total Items: 284\n",
            "ROC-AUC: 0.7791840381179274\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGRdQPAl31ac"
      },
      "source": [
        "#TEST EFFNET:\n",
        "####To test the EffNet trained for spectrogram classification, run the below cell. Similarlty to the procedure above, change the file and folder names of the EffNet state storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_6gPMFm3tuT",
        "outputId": "dea51280-da68-4a8e-9a43-d6faed126ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class EffNetModel(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            efficient_net_type='efficientnet-b0',\n",
        "            num_classes = None,\n",
        "            model_output = 1280\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.efficient_net_type = efficient_net_type\n",
        "\n",
        "        self.efficient_net = EfficientNet.from_pretrained(self.efficient_net_type)\n",
        "        if num_classes is None:\n",
        "            self.output_linear = nn.Identity()\n",
        "        else:\n",
        "            self.output_linear = nn.Linear(1000, num_classes)\n",
        "\n",
        "        self.last = nn.Identity()  # ######################################### This will become the PCA layer\n",
        "        self.activations = list()\n",
        "        self.mode = 'classification'\n",
        "        # self.set_hooks()\n",
        "        self.model_output = model_output\n",
        "\n",
        "    def forward_activations(self, x):\n",
        "        self.activations = list() # self.activations[0]: 1x1280\n",
        "        x = self.efficient_net(x) # 1x1000\n",
        "\n",
        "        if self.model_output == 1280:\n",
        "            self.activations[0] = self.last(self.activations[0])\n",
        "        else:\n",
        "            x = self.last(x)\n",
        "\n",
        "        return x, self.activations\n",
        "\n",
        "    def forward_classification(self, x):\n",
        "        x = self.efficient_net(x)\n",
        "        x = self.output_linear(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.mode == 'classification':\n",
        "            return self.forward_classification(x)\n",
        "        elif self.mode == 'activations':\n",
        "            return self.forward_activations(x)\n",
        "        else:\n",
        "            raise NotImplemented('Model recieved unknown mode')\n",
        "\n",
        "    def get_image_size(self):\n",
        "        return self.efficient_net.get_image_size(self.efficient_net_type)\n",
        "\n",
        "    def set_hooks(self):\n",
        "        def hook(module, inp, out):\n",
        "            self.activations.append(out.squeeze())\n",
        "\n",
        "        self.efficient_net._modules['_avg_pooling'].register_forward_hook(hook)\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "class Pad:\n",
        "  \"\"\"\n",
        "  A class for padding using torch transforms on numpy array.\n",
        "  This is highly tailored to this code...\n",
        "  \"\"\"\n",
        "  def __init__(self, value=0, return_size=224):\n",
        "    self.value = value # Not doing anything. \n",
        "    self.return_size = return_size\n",
        "\n",
        "  def __call__(self,x):\n",
        "    \"\"\"\n",
        "    x:\n",
        "      numpy array [N x M]\n",
        "    \n",
        "    returns:\n",
        "      numpy array [return_size x return_size]\n",
        "    \"\"\"\n",
        "\n",
        "    ax_0 = (self.return_size - x.shape[0])//2 + 1\n",
        "    ax_1 = (self.return_size - x.shape[1]) // 2 + 1\n",
        "\n",
        "    return np.pad(\n",
        "        x.squeeze(),\n",
        "        ((ax_0,ax_0), (ax_1, ax_1))\n",
        "        )[:self.return_size, :self.return_size,np.newaxis]\n",
        "\n",
        "class Repeat_axis:\n",
        "  \"\"\"\n",
        "  EffNet expects RGB images, we have grayscale\n",
        "  \"\"\"\n",
        "  def __init__(self,axis=-1,num=3):\n",
        "    self.axis = axis\n",
        "    self.num = num\n",
        "\n",
        "  def __call__(self,x):\n",
        "    # x is [H x W x C] !!!\n",
        "    return np.repeat(x, self.num, self.axis)\n",
        "\n",
        "trainvaltest_transforms = transforms.Compose([\n",
        "  Pad(5),\n",
        "  Repeat_axis()\n",
        "])\n",
        "\n",
        "for snr in snrs:\n",
        "  print(f\"TRAINING SNR TYPE: {snr}, MODEL: fconvnet3\")\n",
        "  folds = 5\n",
        "  batch_size = 32\n",
        "  model_folder = \"others\"\n",
        "  device = 'cuda'\n",
        "\n",
        "\n",
        "  ######################\n",
        "  ######################\n",
        "  version_number = 1                                    # version number\n",
        "  model_name = f\"effnet_{snr}\"                     # name of file\n",
        "  model = EffNetModel(num_classes=1).to(device)         # model\n",
        "  ######################\n",
        "  ######################\n",
        "\n",
        "  submission =  pd.DataFrame()\n",
        "  submission['segment_id'] = test_df['segment_id']\n",
        "  save_name = f'v{version_number}_{model_name}_final'\n",
        "\n",
        "  for i in range(folds):\n",
        "      submission[f'fold {i}'] = show_validation_accuracy_two(\n",
        "          test_df['iq_sweep_burst'].reshape(list(test_df['iq_sweep_burst'].shape) + [1]),\n",
        "          None, \n",
        "          i, \n",
        "          model_folder, \n",
        "          save_name, \n",
        "          model, \n",
        "          batch_size, \n",
        "          0,\n",
        "          transforms=trainvaltest_transforms\n",
        "          )\n",
        "\n",
        "  submission['prediction'] = submission[[f'fold {j}' for j in range(folds)]].median(1).astype('float')\n",
        "  for col in submission.drop(['segment_id'], axis='columns').columns:\n",
        "    output = pred_description(submission[col], test_df['target_type'].astype(int), True)\n",
        "    print(f\"ROC-AUC {col}: {output['ROC_AUC']}\")\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n",
            "TRAINING SNR TYPE: low_snr, MODEL: fconvnet3\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 0: 0.8168552709946396\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 1: 0.8986003573555689\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 2: 0.8964661504864007\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 3: 0.8672324796505856\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 4: 0.8806333134802462\n",
            "Number of Total Items: 284\n",
            "ROC-AUC prediction: 0.8876315267024022\n",
            "TRAINING SNR TYPE: high_snr, MODEL: fconvnet3\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 0: 0.638872344649593\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 1: 0.7708953742306929\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 2: 0.7601250744490768\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 3: 0.7834524518562637\n",
            "Number of Total Items: 284\n",
            "ROC-AUC fold 4: 0.7304447091522732\n",
            "Number of Total Items: 284\n",
            "ROC-AUC prediction: 0.76508834623784\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}